{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Programming with Energy Data\n",
    "\n",
    "Data from the [National Grid ESO API ](https://www.nationalgrideso.com/data-portal/api-guidance). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and installs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "The data below is retrieved from the National Grid Energy API, consisting of time series around electricity flow, electricity generation, capacity, pricing, and carbon. \n",
    "\n",
    "Each of the calls consist of multiple time series and these are combined into a single dataframe and transposed for the clustering algorithm. A total of 34 time series, each of length 17520 are used to test the genetic clustering algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- Shape of dataframes ----- \n",
      " --- 2022 Demand:  (17520, 19)\n",
      " --- 2023 Demand:  (17520, 21)\n",
      " --- 2022 Prices: (17520, 6)\n",
      " --- 2023 Carbon: (17520, 16)\n"
     ]
    }
   ],
   "source": [
    "# API Calls to the Britain national grid API. Calling to retrieve historic electricity demand,\n",
    "# interconnector, wind and solar outturn, and carbon intensity data for 2022 and/or 2023.\n",
    "\n",
    "URL = 'https://api.nationalgrideso.com/api/3/action/datastore_search_sql?sql=SELECT * FROM \"bb44a1b5-75b1-4db2-8491-257f23385006\"'\n",
    "response = requests.get(URL).json()\n",
    "URL2 = 'https://api.nationalgrideso.com/api/3/action/datastore_search_sql?sql=SELECT * FROM \"bf5ab335-9b40-4ea4-b93a-ab4af7bce003\"'\n",
    "response2 = requests.get(URL2).json()\n",
    "URL3 = 'https://api.nationalgrideso.com/api/3/action/datastore_search_sql?sql=SELECT * FROM \"3372646d-419f-4599-97a9-6bb4e7e32862\"'\n",
    "response3 = requests.get(URL3).json()\n",
    "URL4 = 'https://api.nationalgrideso.com/api/3/action/datastore_search_sql?sql=SELECT * FROM \"c16b0e19-c02a-44a8-ba05-4db2c0545a2a\"'\n",
    "response4 = requests.get(URL4).json()\n",
    "\n",
    "\n",
    "# Converting responses from json into pandas dataframe\n",
    "df_demand_2022 = pd.json_normalize(\n",
    "    response[\"result\"][\"records\"],\n",
    "    meta=[\n",
    "        \"IFA_FLOW\",\n",
    "        \"TSD\",\n",
    "        \"VIKING_FLOW\",\n",
    "        \"IFA2_FLOW\",\n",
    "        \"EMBEDDED_WIND_GENERATION\",\n",
    "        \"ND\",\n",
    "        \"MOYLE_FLOW\",\n",
    "        \"NEMO_FLOW\",\n",
    "        \"ELECLINK_FLOW\",\n",
    "        \"PUMP_STORAGE_PUMPING\",\n",
    "        \"EMBEDDED_WIND_CAPACITY\",\n",
    "        \"SETTLEMENT_DATE\",\n",
    "        \"ENGLAND_WALES_DEMAND\",\n",
    "        \"EMBEDDED_SOLAR_CAPACITY\",\n",
    "        \"SCOTTISH_TRANSFER\",\n",
    "        \"NON_BM_STOR\",\n",
    "        \"_FULL_TEXT\",\n",
    "        \"SETTLEMENT_PERIOD\",\n",
    "        \"EAST_WEST_FLOW\",\n",
    "        \"NSL_FLOW\",\n",
    "        \"BRITNED_FLOW\",\n",
    "        \"_ID\",\n",
    "        \"EMBEDDED_SOLAR_GENERATION\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_demand_2023 = pd.json_normalize(\n",
    "    response2[\"result\"][\"records\"],\n",
    "    meta=[\n",
    "        \"IFA_FLOW\",\n",
    "        \"TSD\",\n",
    "        \"VIKING_FLOW\",\n",
    "        \"IFA2_FLOW\",\n",
    "        \"EMBEDDED_WIND_GENERATION\",\n",
    "        \"ND\",\n",
    "        \"MOYLE_FLOW\",\n",
    "        \"NEMO_FLOW\",\n",
    "        \"ELECLINK_FLOW\",\n",
    "        \"PUMP_STORAGE_PUMPING\",\n",
    "        \"EMBEDDED_WIND_CAPACITY\",\n",
    "        \"SETTLEMENT_DATE\",\n",
    "        \"ENGLAND_WALES_DEMAND\",\n",
    "        \"EMBEDDED_SOLAR_CAPACITY\",\n",
    "        \"SCOTTISH_TRANSFER\",\n",
    "        \"NON_BM_STOR\",\n",
    "        \"_FULL_TEXT\",\n",
    "        \"SETTLEMENT_PERIOD\",\n",
    "        \"EAST_WEST_FLOW\",\n",
    "        \"NSL_FLOW\",\n",
    "        \"BRITNED_FLOW\",\n",
    "        \"_ID\",\n",
    "        \"EMBEDDED_SOLAR_GENERATION\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_historic_prices_2022 = pd.json_normalize(\n",
    "    response3[\"result\"][\"records\"],\n",
    "    meta=[\n",
    "        \"Settlement Period\",\n",
    "        \"Half-hourly Charge\",\n",
    "        \"Run Type\",\n",
    "        \"Total Daily BSUoS Charge\",\n",
    "        \"_full_text\",\n",
    "        \"BSUoS Price (Â£/MWh Hour)\",\n",
    "        \"Settlement Day\",\n",
    "        \"_id\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_carbon = pd.json_normalize(\n",
    "    response4[\"result\"][\"records\"],\n",
    "    meta=[\n",
    "        \"East Midlands\",\n",
    "        \"East England\",\n",
    "        \"West Midlands\",\n",
    "        \"North Scotland\",\n",
    "        \"South Scotland\",\n",
    "        \"_full_text\",\n",
    "        \"South West England\",\n",
    "        \"datetime\",\n",
    "        \"North Wales and Merseyside\",\n",
    "        \"North East England\",\n",
    "        \"South East England\",\n",
    "        \"South Wales\",\n",
    "        \"North West England\",\n",
    "        \"Yorkshire\",\n",
    "        \"London\",\n",
    "        \"_id\",\n",
    "        \"South England\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Conversions to datetime for extracting data for specific years\n",
    "df_historic_prices_2022[\"Settlement Day\"] = pd.to_datetime(\n",
    "    df_historic_prices_2022[\"Settlement Day\"]\n",
    ")\n",
    "df_historic_prices_2022 = df_historic_prices_2022[\n",
    "    df_historic_prices_2022[\"Settlement Day\"].dt.year == 2022\n",
    "]\n",
    "\n",
    "df_carbon[\"datetime\"] = pd.to_datetime(df_carbon[\"datetime\"])\n",
    "df_carbon_2023 = df_carbon[df_carbon[\"datetime\"].dt.year == 2023]\n",
    "\n",
    "# Dropping unused columns for future concatenation\n",
    "df_demand_2022 = df_demand_2022.drop([\"_full_text\", \"NON_BM_STOR\"], axis=1)\n",
    "df_demand_2023 = df_demand_2023.drop([\"_full_text\", \"NON_BM_STOR\"], axis=1)\n",
    "df_historic_prices_2022 = df_historic_prices_2022.drop(\n",
    "    [\"Run Type\", \"_full_text\"], axis=1\n",
    ")\n",
    "df_carbon_2023 = df_carbon_2023.drop([\"_full_text\"], axis=1)\n",
    "\n",
    "print(\" ----- Shape of dataframes ----- \")\n",
    "print(\" --- 2022 Demand: \", df_demand_2022.shape)\n",
    "print(\" --- 2023 Demand: \", df_demand_2023.shape)\n",
    "print(\" --- 2022 Prices:\", df_historic_prices_2022.shape)\n",
    "print(\" --- 2023 Carbon:\", df_carbon_2023.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls: 0\n"
     ]
    }
   ],
   "source": [
    "# Dropping id columns and now unused date columns.\n",
    "# Only want the time series that will be clustered - each are of size 17520\n",
    "# so the \"_id\" column is able to be dropped.\n",
    "\n",
    "df_demand_2022_noid = df_demand_2022.drop(\n",
    "    [\"_id\", \"SETTLEMENT_DATE\", \"SETTLEMENT_PERIOD\"], axis=1\n",
    ")\n",
    "df_demand_2023_noid = df_demand_2023.drop(\n",
    "    [\"_id\", \"SETTLEMENT_DATE\", \"SETTLEMENT_PERIOD\"], axis=1\n",
    ")\n",
    "df_demand_2023_noid.columns = [str(col) + \"_2\" for col in df_demand_2023_noid.columns]\n",
    "df_historic_prices_2022_noid = df_historic_prices_2022.drop(\n",
    "    [\"Settlement Period\", \"Settlement Day\", \"_id\"], axis=1\n",
    ")\n",
    "df_carbon_2023_noid = df_carbon_2023.drop([\"_id\", \"datetime\"], axis=1)\n",
    "\n",
    "# Concatenating the dataframes.\n",
    "df_full = pd.concat(\n",
    "    [\n",
    "        df_historic_prices_2022_noid.reset_index().drop(\"index\", axis=1, inplace=True),\n",
    "        df_demand_2022_noid,\n",
    "        df_demand_2023_noid,\n",
    "        df_carbon_2023_noid.reset_index().drop(\"index\", axis=1, inplace=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Must perform scaling since clustering algorithms work on similarity/distance\n",
    "df_full = StandardScaler().fit_transform(df_full)\n",
    "df_full_transposed = df_full.transpose()\n",
    "\n",
    "# Checking for any null values in the time series\n",
    "null_count_full = 0\n",
    "for curr_list in df_full_transposed:\n",
    "    null_count = sum(1 for item in curr_list if item is None)\n",
    "    null_count_full += null_count\n",
    "\n",
    "print(\"Number of nulls:\", null_count_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries for Model Generation\n",
    "\n",
    "We are going to instantiate multiple clustering models as our initial population for the algorithm, and use these similarly to mutate and crossover algorithms. The models used in the algorithm are below, with associated parameters to adjust:\n",
    "- KMeans: number of clusters, max iteration, tolerance\n",
    "- KMedoids: number of clusters, metric, method, max iteration\n",
    "- DBSCAN: epsilon, minimum samples, metric\n",
    "- HDBSCAN: epsilon, minimum samples, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining which parameters are appropriate to adjust for each clustering model\n",
    "\n",
    "model_list = [\"KMeans\", \"KMedoids\", \"DBSCAN\", \"HDBSCAN\"]\n",
    "\n",
    "list_dict_model_params = [\n",
    "    {\"KMeans\": [\"n_clusters\", \"max_iter\", \"tol\"]},\n",
    "    {\"KMedoids\": [\"n_clusters\", \"metric_1\", \"method\", \"max_iter\"]},\n",
    "    {\"DBSCAN\": [\"eps\", \"min_samples\", \"metric_1\"]},\n",
    "    {\"HDBSCAN\": [\"metric_2\", \"min_samples\", \"eps\"]},\n",
    "]\n",
    "\n",
    "# Defining which parameter values each model can take\n",
    "dict_param_values = {\n",
    "    \"n_clusters\": list(range(2, 11)),\n",
    "    \"max_iter\": list(range(50, 510, 10)),\n",
    "    \"tol\": list(np.arange(0.0001, 0.1001, 0.001)),\n",
    "    \"metric_1\": [\n",
    "        \"euclidean\",\n",
    "        \"cosine\",\n",
    "        \"haversine\",\n",
    "        \"l2\",\n",
    "        \"cityblock\",\n",
    "        \"l1\",\n",
    "        \"manhattan\",\n",
    "    ],\n",
    "    \"metric_2\": [\n",
    "        \"l2\",\n",
    "        \"canberra\",\n",
    "        \"manhattan\",\n",
    "        \"euclidean\",\n",
    "        \"braycurtis\",\n",
    "        \"chebyshev\",\n",
    "        \"hamming\",\n",
    "    ],\n",
    "    \"method\": [\"alternate\", \"pam\"],\n",
    "    \"eps\": list(np.arange(0.1, 4.1, 0.1)),\n",
    "    \"min_samples\": list(range(3, 11)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for the Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The import evolution_fns includes all functions required for evolution\n",
    "import evolution_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top model: KMeans(max_iter=50, tol=0.0061), associated score: 0.25340341983699355\n",
      "Top model: KMeans(max_iter=50, tol=0.041100000000000005), associated score: 0.26062967012871296\n",
      "Top model: KMeans(tol=0.032100000000000004), associated score: 0.2842059653587293\n",
      "Top model: KMeans(tol=0.032100000000000004), associated score: 0.27468539890174\n",
      "Top model: KMeans(max_iter=90, tol=0.0941), associated score: 0.28306130060266455\n",
      "Top model: KMeans(max_iter=50, tol=0.0061), associated score: 0.28317910424671267\n",
      "Top model: KMeans(max_iter=50, tol=0.0901), associated score: 0.2842059653587293\n",
      "Top model: KMeans(max_iter=50, tol=0.041100000000000005), associated score: 0.2868184018099966\n",
      "Top model: KMeans(max_iter=50, tol=0.0061), associated score: 0.28306130060266455\n",
      "Top model: KMeans(max_iter=380, tol=0.032100000000000004), associated score: 0.2875367162737374\n",
      "Top model: KMeans(max_iter=50, tol=0.0751), associated score: 0.28385385434315336\n",
      "Top model: KMeans(max_iter=160, tol=0.06910000000000001), associated score: 0.2868184018099966\n",
      "Top model: KMeans(max_iter=50, tol=0.0751), associated score: 0.2875367162737374\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.29727219957466144\n",
      "Top model: KMeans(max_iter=50, tol=0.0061), associated score: 0.2842059653587293\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.30208341778328635\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.30759275208171055\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.3063152510243774\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.2933779502780625\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.3226796662985823\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.31743999685079555\n",
      "Top model: KMeans(max_iter=50, tol=0.032100000000000004), associated score: 0.2868184018099966\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.3064307401647855\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.3140521547359082\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.30454195705119835\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.3116664364498815\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.3116664364498815\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.3138412933519657\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.31843003087318367\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.32352768205051846\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.31471874124499927\n",
      "Top model: KMeans(max_iter=260, n_clusters=10, tol=0.032100000000000004), associated score: 0.31743999685079555\n",
      "Top model: KMeans(max_iter=390, n_clusters=10, tol=0.032100000000000004), associated score: 0.31008440664929227\n",
      "Top model: KMeans(max_iter=380, n_clusters=10, tol=0.032100000000000004), associated score: 0.3226796662985823\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.31843003087318367\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.31743999685079555\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.31471874124499927\n",
      "Top model: KMeans(max_iter=390, n_clusters=10, tol=0.032100000000000004), associated score: 0.31336945757920026\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.0731), associated score: 0.32147683039574265\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.0731), associated score: 0.31846511145953965\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.0731), associated score: 0.3226796662985823\n",
      "Top model: KMeans(max_iter=390, n_clusters=10, tol=0.032100000000000004), associated score: 0.3116664364498815\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004), associated score: 0.31008440664929227\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "Top model: KMedoids(max_iter=330, method='pam', metric='manhattan', n_clusters=10), associated score: 0.30757942688381634\n",
      "The top ten models based on silhoutte score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(KMeans(max_iter=380, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.3226796662985823),\n",
       " (KMeans(max_iter=50, n_clusters=10, tol=0.0731), 0.3226796662985823),\n",
       " (KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.31843003087318367),\n",
       " (KMeans(max_iter=260, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.31743999685079555),\n",
       " (KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.31743999685079555),\n",
       " (KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.31471874124499927),\n",
       " (KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.31471874124499927),\n",
       " (KMeans(max_iter=50, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.3138412933519657),\n",
       " (KMeans(max_iter=390, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.31336945757920026),\n",
       " (KMeans(max_iter=390, n_clusters=10, tol=0.032100000000000004),\n",
       "  0.3116664364498815)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The evolution function is an iterative algorithm that comprises of an initial population,\n",
    "# fitness evalution, selection, crossover, and mutation. Returns the top 10 models.\n",
    "\n",
    "evolution_fns.evolution(\n",
    "    model_params=list_dict_model_params,\n",
    "    param_values=dict_param_values,\n",
    "    init_population_num=20,\n",
    "    df=df_full_transposed,\n",
    "    selection_param=0.8,\n",
    "    crossover_repeat=2,\n",
    "    mutation_repeat=2,\n",
    "    cutoff_score=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
